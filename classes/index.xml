<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Teaching | Rycolab</title>
    <link>https://rycolab.github.io/classes/</link>
      <atom:link href="https://rycolab.github.io/classes/index.xml" rel="self" type="application/rss+xml" />
    <description>Teaching</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language>
    <image>
      <url>https://rycolab.github.io/images/logo_hu5446c388f937c2fb02cc384744e2d784_428800_300x300_fit_lanczos_2.png</url>
      <title>Teaching</title>
      <link>https://rycolab.github.io/classes/</link>
    </image>
    
    <item>
      <title>Natural Language Processing</title>
      <link>https://rycolab.github.io/classes/intro-nlp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://rycolab.github.io/classes/intro-nlp/</guid>
      <description>

&lt;h2 id=&#34;course-description&#34;&gt;Course Description&lt;/h2&gt;

&lt;p&gt;This course presents topics in natural language processing with an emphasis on modern techniques, primarily focusing on statistical and deep learning approaches. The course provides an overview of the primary areas of research in language processing as well as a detailed exploration of the models and techniques used both in research and in commercial natural language systems.e processing as well as a detailed exploration of the models and techniques used both in research and in commercial natural language systems.&lt;/p&gt;

&lt;p&gt;The objective of the course is to learn the basic concepts in the statistical processing of natural languages. The course will be project-oriented so that the students can also gain hands-on experience with state-of-the-art tools and techniques.&lt;/p&gt;

&lt;h4 id=&#34;grading&#34;&gt;Grading&lt;/h4&gt;

&lt;p&gt;Marks for the course will be determined by the following formula:&lt;br /&gt;
* 70% Final Exam&lt;br /&gt;
* 30% Course Project/Assignment&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Lectures:&lt;/strong&gt; Mon 12-14h Zoom (link to be emailed and posted on piazza day of lecture)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Discussion Sections:&lt;/strong&gt; Wednesday 13-14h Zoom (link to be emailed and posted on piazza day of discussion)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Textbooks:&lt;/strong&gt; &lt;a href=&#34;https://www.amazon.de/Jacob-Eisenstein/dp/0262042843/ref=sr_1_1?__mk_de_DE=%C3%85M%C3%85%C5%BD%C3%95%C3%91&amp;amp;crid=30OMHV1C018JY&amp;amp;dchild=1&amp;amp;keywords=introduction+to+natural+language+processing&amp;amp;qid=1598878964&amp;amp;sprefix=introduction+to+na%2Caps%2C148&amp;amp;sr=8-1&#34;&gt;Introduction to Natural Language Processing (Eisenstein)&lt;/a&gt;&lt;br /&gt;
&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp; &lt;a href=&#34;https://www.deeplearningbook.org/&#34;&gt;Deep Learning (Goodfellow, Bengio and Courville)&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;news&#34;&gt;News&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;31.08&lt;/strong&gt; &amp;emsp; Class website is online!&lt;br /&gt;
&lt;strong&gt;31.08&lt;/strong&gt; &amp;emsp; We are using piazza as our discussion forum. Please enroll &lt;a href=&#34;https://www.piazza.com/ethz.ch/fall2020/252300500l&#34;&gt;here&lt;/a&gt;.&lt;br /&gt;
&lt;strong&gt;21.09&lt;/strong&gt; &amp;emsp; First lecture.&lt;br /&gt;
&lt;strong&gt;30.09&lt;/strong&gt; &amp;emsp; First discussion section.&lt;br /&gt;
&lt;strong&gt;16.10&lt;/strong&gt; &amp;emsp; &lt;a href=&#34;materials/project_guidelines.pdf&#34;&gt;Project guidelines&lt;/a&gt; released.&lt;br /&gt;
&lt;strong&gt;23.10&lt;/strong&gt; &amp;emsp; &lt;a href=&#34;materials/assignment.pdf&#34;&gt;First part&lt;/a&gt; of course assignment released.&lt;br /&gt;
&lt;strong&gt;1.11&lt;/strong&gt; &amp;emsp;&amp;ensp; Project proposals due for groups electing to do research project (submission instructions to come).&lt;/p&gt;

&lt;h2 id=&#34;syllabus&#34;&gt;Syllabus&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Disclaimer:&lt;/strong&gt; This is the first year the class is being taught in this format. It will progress, and may change, as the semester carries on.






  



  
  











&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://rycolab.github.io/classes/intro-nlp/roller-coaster_hu4858935a858db53d3a5f68c44ca972c4_671304_2000x2000_fit_lanczos_2.png&#34; &gt;


  &lt;img data-src=&#34;https://rycolab.github.io/classes/intro-nlp/roller-coaster_hu4858935a858db53d3a5f68c44ca972c4_671304_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;842&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;table class=&#34;table&#34;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th scope=&#34;col&#34; style=&#39;white-space:nowrap&#39;&gt;Week&lt;/th&gt;
      &lt;th scope=&#34;col&#34; style=&#39;white-space:nowrap&#39;&gt;Date&amp;emsp;&amp;emsp;&lt;/th&gt;
      &lt;th scope=&#34;col&#34; style=&#39;white-space:nowrap&#39;&gt;Topic&lt;/th&gt;
      &lt;th scope=&#34;col&#34; style=&#39;white-space:nowrap&#39;&gt;Slides&amp;emsp;&amp;emsp;&lt;/th&gt;
      &lt;th scope=&#34;col&#34; style=&#39;white-space:nowrap&#39;&gt;Readings&lt;/th&gt;
      &lt;th scope=&#34;col&#34; style=&#39;white-space:nowrap&#39;&gt;Supplementary Material&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th scope=&#34;row&#34;&gt;-&lt;/th&gt;
      &lt;td&gt;14.09.20&lt;/td&gt;
      &lt;td&gt;Knabenschiessen (no class)&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th scope=&#34;row&#34;&gt;1&lt;/th&gt;
      &lt;td&gt;21.09.20&lt;/td&gt;
      &lt;td&gt;Introduction to Natural Language&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;slides/lecture1.pdf&#34;&gt;Lecture 1&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;Eisenstein Ch. 1&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th scope=&#34;row&#34;&gt;2&lt;/th&gt;
      &lt;td&gt;28.09.20&lt;/td&gt;
      &lt;td&gt;Backpropagation&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;slides/lecture2.pdf&#34;&gt;Lecture 2&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;
        &lt;a href=&#34;https://colah.github.io/posts/2015-08-Backprop/&#34;&gt;Chris Olah&amp;rsquo;s Blog&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;https://people.cs.umass.edu/~domke/courses/sml2011/08autodiff_nnets.pdf&#34;&gt;Justin Domke’s Notes&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;https://timvieira.github.io/blog/post/2017/08/18/backprop-is-not-just-the-chain-rule/&#34;&gt;Tim Vieira’s Blog&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;https://ee227c.github.io/notes/ee227c-lecture16.pdf&#34;&gt;Moritz Hardt’s Notes&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;https://core.ac.uk/download/pdf/82480031.pdf&#34;&gt;Baur and Strassen (1983)&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;https://www.amazon.co.uk/Evaluating-Derivatives-Principles-Algorithmic-Differentiation/dp/0898716594/ref=sr_1_1?dchild=1&amp;keywords=griewank&amp;qid=1598888684&amp;s=books&amp;sr=1-1&#34;&gt;Griewank and Walter (2008)&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;https://www.cs.jhu.edu/~jason/papers/eisner.spnlp16.pdf&#34;&gt;Eisner (2016)&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;materials/mlp_comp_graph.pdf&#34;&gt;Computation Graph for MLP&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;materials/comp_graph.pdf&#34;&gt;Computation Graph Example&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th scope=&#34;row&#34;&gt;3&lt;/th&gt;
      &lt;td&gt;5.10.20 &lt;/td&gt;
      &lt;td&gt;Log-Linear Modeling&amp;mdash;Meet the Softmax&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;slides/lecture3.pdf&#34;&gt;Lecture 3&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;slides/log-linear-tutorial.pdf&#34;&gt;Tutorial&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;Eisenstein Ch. 2&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://www.cs.jhu.edu/~jason/papers/ferraro+eisner.tnlp13.pdf&#34;&gt;Ferraro and Eisner (2013)&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;http://cs.jhu.edu/~jason/tutorials/loglin/further.html&#34;&gt;Jason Eisner’s list of further resources on log-linear modeling&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th scope=&#34;row&#34;&gt;4&lt;/th&gt;
      &lt;td&gt;12.10.20&lt;/td&gt;
      &lt;td&gt;Sentiment Analysis with Multi-layer Perceptrons&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;slides/lecture4.pdf&#34;&gt;Lecture 4&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;slides/recnn-tutorial.pdf&#34;&gt;Tutorial&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;Eisenstein Ch. 3 and Ch. 4&lt;/br&gt;Goodfellow, Bengio and Courville Ch. 6&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Universal_approximation_theorem&#34;&gt;Wikipedia&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.441.7873&amp;rep=rep1&amp;type=pdf&#34;&gt;Cybenko (1989)&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;https://arxiv.org/pdf/1710.11278.pdf&#34;&gt;Hanin and Selke (2018)&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;https://www.cs.cornell.edu/home/llee/omsa/omsa.pdf&#34;&gt;Pang and Lee (2008)&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;https://www.aclweb.org/anthology/P15-1162/&#34;&gt;Iyyer et al. (2015)&lt;/a&gt;&lt;/br&gt;
      &lt;a href=&#34;https://arxiv.org/pdf/1411.2738.pdf&#34;&gt;word2vec Parameter Learning Explained&lt;/a&gt;&lt;/br&gt;
    &lt;a href=&#34;https://arxiv.org/pdf/1402.3722.pdf&#34;&gt;word2vec Explained&lt;/a&gt;&lt;/br&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th scope=&#34;row&#34;&gt;5&lt;/th&gt;
      &lt;td&gt;19.10.20&lt;/td&gt;
      &lt;td&gt;Language Modeling with &lt;em&gt;n&lt;/em&gt;-grams and LSTMs&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;slides/lecture5.pdf&#34;&gt;Lecture 5&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;slides/lang-model-tutorial.pdf&#34;&gt;Tutorial&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;Eisenstein Ch. 6&lt;/br&gt;Goodfellow, Bengio and Courville Ch. 10&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://nlp.stanford.edu/~wcmac/papers/20050421-smoothing-tutorial.pdf&#34;&gt;Good Tutorial on n-gram smoothing&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;https://en.wikipedia.org/wiki/Good%E2%80%93Turing_frequency_estimation&#34;&gt;Good–Turing Smoothing&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;https://ieeexplore.ieee.org/document/479394&#34;&gt;Kneser and Ney (1995)&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf&#34;&gt;Bengio et al. (2003)&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;https://www.isca-speech.org/archive/archive_papers/interspeech_2010/i10_1045.pdf&#34;&gt;Mikolov et al. (2010)&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th scope=&#34;row&#34;&gt;6&lt;/th&gt;
      &lt;td&gt;26.10.20&lt;/td&gt;
      &lt;td&gt;Part-of-Speech Tagging with CRFs&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;slides/lecture6.pdf&#34;&gt;Lecture 6&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;Eisenstein Ch. 7 and 8&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://timvieira.github.io/blog/post/2015/04/29/multiclass-logistic-regression-and-conditional-random-fields-are-the-same-thing/&#34;&gt;Tim Vieira&amp;rsquo;s Blog&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;https://dl.acm.org/doi/10.5555/645529.658277&#34;&gt;McCallum et al. (2000)&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;https://repository.upenn.edu/cgi/viewcontent.cgi?article=1162&amp;context=cis_papers&#34;&gt;Lafferty et al. (2001)&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;https://homepages.inf.ed.ac.uk/csutton/publications/crftut-fnt.pdf&#34;&gt;Sutton and McCallum (2011)&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;https://mitpress.mit.edu/books/probabilistic-graphical-models&#34;&gt;Koller and Friedman (2009)&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th scope=&#34;row&#34;&gt;7&lt;/th&gt;
      &lt;td&gt;2.11.20&lt;/td&gt;
      &lt;td&gt;Context-Free Parsing with CKY&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;Eisenstein Ch. 10&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;http://www.cs.columbia.edu/~mcollins/io.pdf&#34;&gt;The Inside-Outside Algorithm&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;https://www.cs.jhu.edu/~jason/465/PowerPoint/lect08-parse.ppt&#34;&gt;Jason Eisner’s Slides&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;https://www.ideals.illinois.edu/handle/2142/74304&#34;&gt;Kasami (1966)&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S001999586780007X?via%3Dihub&#34;&gt;Younger (1967)&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;http://www.softwarepreservation.org/projects/FORTRAN/CockeSchwartz_ProgLangCompilers.pdf&#34;&gt;Cocke and Schwartz (1970)&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th scope=&#34;row&#34;&gt;8&lt;/th&gt;
      &lt;td&gt;9.11.20&lt;/td&gt;
      &lt;td&gt;Dependency Parsing with the Matrix-Tree Theorem&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;Eisenstein Ch. 11&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://www.aclweb.org/anthology/D07-1015/&#34;&gt;Koo et al. (2007)&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;https://www.aclweb.org/anthology/D07-1014/&#34;&gt;Smith and Smith (2007)&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;https://www.aclweb.org/anthology/W07-2216/&#34;&gt;McDonald and Satta (2007)&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;https://www.morganclaypool.com/doi/abs/10.2200/S00169ED1V01Y200901HLT002&#34;&gt;McDonald, Kübler and Nivre (2009)&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th scope=&#34;row&#34;&gt;9&lt;/th&gt;
      &lt;td&gt;16.11.20&lt;/td&gt;
      &lt;td&gt;Transliteration with WFSTs&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;Eisenstein Ch. 9&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://www.aclweb.org/anthology/J98-4003.pdf&#34;&gt;Knight and Graehl (1998)&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;https://cs.nyu.edu/~mohri/pub/hbka.pdf&#34;&gt;Mohri, Pereira and Riley (2008)&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th scope=&#34;row&#34;&gt;10&lt;/th&gt;
      &lt;td&gt;23.11.20&lt;/td&gt;
      &lt;td&gt;No Class (NAACL Deadline)&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th scope=&#34;row&#34;&gt;11&lt;/th&gt;
      &lt;td&gt;30.11.20&lt;/td&gt;
      &lt;td&gt;Machine Translation with Transformers&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;Eisenstein Ch. 18&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://www.amazon.com/gp/product/1108497322/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1108497322&amp;linkCode=as2&amp;tag=statismachint-20&amp;linkId=ca7b8315b48f309c992019761c3ac4e4&#34;&gt;Neural Machine Translation&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf&#34;&gt;Vaswani et al. (2017)&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;https://www.aclweb.org/anthology/W18-2509/&#34;&gt;Rush (2018)&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th scope=&#34;row&#34;&gt;12&lt;/th&gt;
      &lt;td&gt;7.12.20&lt;/td&gt;
      &lt;td&gt;Axes of Modeling&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th scope=&#34;row&#34;&gt;13&lt;/th&gt;
      &lt;td&gt;14.12.20&lt;/td&gt;
      &lt;td&gt;Bias and Fairness in NLP&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-debiasing-word-embeddings.pdf&#34;&gt;Bolukabasi et al. (2016)&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;https://arxiv.org/abs/1903.03862&#34;&gt;Gonen and Goldberg (2019)&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;https://arxiv.org/abs/1909.00871&#34;&gt;Hall Maudslay et al. (2019)&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;https://arxiv.org/abs/2009.09435&#34;&gt;Vargas and Cotterell (2020)&lt;/a&gt;&lt;/br&gt;
        &lt;a href=&#34;http://ciml.info/dl/v0_99/ciml-v0_99-ch08.pdf&#34;&gt;A Course in Machine Learning Chapter 8&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;&lt;/p&gt;

&lt;p&gt;&lt;/tbody&gt;
&lt;/table&gt;&lt;/p&gt;

&lt;h2 id=&#34;course-project-assignment&#34;&gt;Course Project/Assignment&lt;/h2&gt;

&lt;p&gt;Every student has the option of completing &lt;em&gt;either&lt;/em&gt; a research project or a structured assignment. The course project/assigment will be worth 30% of your final mark. The project would be an open-ended research project where students reimplement an existing research paper or perform novel research if they are so inclined. Please find the guidelines &lt;a href=&#34;materials/project_guidelines.pdf&#34;&gt;here&lt;/a&gt;. In the assignment, some of the questions would be more theoretical and resemble the questions you will see on the final exam. However, there may also be a large coding portion in the assignment, which would not look like the exam questions. For instance, we may ask you to implement a recurrent neural dependency parser. Please find the first portion of the assignment &lt;a href=&#34;materials/assignment.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Assignments must be completed individually. Projects can be completed in groups of up to 4. If you choose to do the project, we require a proposal no later than November 1, 2020 23:59 CEST. Please see project guidelines for content/formatting instructions; email proposals to Clara (email address below) by the deadline. All projects/assigments will be due at the end of the semester.&lt;/p&gt;

&lt;h2 id=&#34;contact&#34;&gt;Contact&lt;/h2&gt;

&lt;p&gt;You can ask questions on &lt;a href=&#34;https://www.piazza.com/ethz.ch/fall2020/252300500l&#34;&gt;piazza&lt;/a&gt;. Please post questions there, so others can see them and share in the discussion.&lt;/p&gt;

&lt;p&gt;If you have questions which are not of general interest, please don&amp;rsquo;t hesitate to contact us directly.&lt;/p&gt;

&lt;table class=&#34;table&#34;&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Lecturer&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;mailto:ryan.cotterell@inf.ethz.ch&#34;&gt;Ryan Cotterell&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Teaching Assistants&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;mailto:meistecl@inf.ethz.ch&#34;&gt;Clara Meister&lt;/a&gt;, &lt;a href=&#34;mailto:niklas.stoehr@inf.ethz.ch&#34;&gt;Niklas Stoehr&lt;/a&gt;, &lt;a href=&#34;mailto:pinjia.he@inf.ethz.ch&#34;&gt;Pinjia He&lt;/a&gt;, &lt;a href=&#34;mailto:mkuznetsova@inf.ethz.ch&#34;&gt;Rita Kuznetsova&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    
  &lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
  </channel>
</rss>
